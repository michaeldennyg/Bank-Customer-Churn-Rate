{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af31a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31a722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = r\"C:\\Users\\micha\\Bank Customer Churn Prediction\\Bank Customer Churn Prediction.csv\"\n",
    "df = pd.read_csv(csv_url, index_col=0)\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7278dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5016666666666667\n",
      "Precision: 0.24294117647058824\n",
      "Recall: 0.6650563607085346\n",
      "F1-Score: 0.35588108573890564\n",
      "ROC-AUC Score: 0.5862596701275723\n",
      "Confusion Matrix:\n",
      "[[1092 1287]\n",
      " [ 208  413]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.46      0.59      2379\n",
      "           1       0.24      0.67      0.36       621\n",
      "\n",
      "    accuracy                           0.50      3000\n",
      "   macro avg       0.54      0.56      0.47      3000\n",
      "weighted avg       0.72      0.50      0.54      3000\n",
      "\n",
      "Accuracy: 0.5016666666666667\n",
      "Confusion Matrix:\n",
      "[[1092 1287]\n",
      " [ 208  413]]\n"
     ]
    }
   ],
   "source": [
    "# features and target x=features, y=target\n",
    "features = df[['credit_score', 'tenure', 'balance', 'active_member']]\n",
    "target = df['churn']\n",
    "\n",
    "# churn and active_member \n",
    "df['churn'] = df['churn'].map({'Yes': 1, 'No': 0})\n",
    "df['churn'].value_counts()\n",
    "\n",
    "# Train-test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.30)\n",
    "\n",
    "# Replace 'Yes' with 1 in the target\n",
    "target_train.replace({'Yes': 1}, inplace=True)\n",
    "target_test.replace({'Yes': 1}, inplace=True)\n",
    "\n",
    "# Handle missing values in 'active_member' as negatives (0)\n",
    "features_train['active_member'] = features_train['active_member'].fillna(0)\n",
    "features_test['active_member'] = features_test['active_member'].fillna(0)\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(target_test, predictions)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(target_test, predictions)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# F1-score\n",
    "f1 = f1_score(target_test, predictions)\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# ROC-AUC score\n",
    "roc_auc = roc_auc_score(target_test, model.predict_proba(features_test)[:, 1])\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(target_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(target_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(target_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707b17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
